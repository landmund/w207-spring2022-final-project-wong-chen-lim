{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "860109f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T01:45:03.471158Z",
     "iopub.status.busy": "2022-04-14T01:45:03.466741Z",
     "iopub.status.idle": "2022-04-14T01:45:04.623426Z",
     "shell.execute_reply": "2022-04-14T01:45:04.622462Z"
    },
    "papermill": {
     "duration": 1.182147,
     "end_time": "2022-04-14T01:45:04.623642",
     "exception": false,
     "start_time": "2022-04-14T01:45:03.441495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"/opt/conda/bin/kaggle\", line 5, in <module>\r\n",
      "    from kaggle.cli import main\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/kaggle/__init__.py\", line 23, in <module>\r\n",
      "    api.authenticate()\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/kaggle/api/kaggle_api_extended.py\", line 166, in authenticate\r\n",
      "    self.config_file, self.config_dir))\r\n",
      "OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\r\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d justinrwong/cnn-species-sample6750-ep50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da7762f2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-04-14T01:45:04.669836Z",
     "iopub.status.busy": "2022-04-14T01:45:04.669070Z",
     "iopub.status.idle": "2022-04-14T01:45:07.264197Z",
     "shell.execute_reply": "2022-04-14T01:45:07.263620Z",
     "shell.execute_reply.started": "2022-04-14T01:40:15.825180Z"
    },
    "papermill": {
     "duration": 2.625243,
     "end_time": "2022-04-14T01:45:07.264351",
     "exception": false,
     "start_time": "2022-04-14T01:45:04.639108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "from numpy import save, load\n",
    "from random import seed\n",
    "from os import listdir\n",
    "from shutil import copyfile\n",
    "from random import seed\n",
    "from random import random\n",
    "\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from contextlib import contextmanager\n",
    "from multiprocessing.pool import ThreadPool, Pool\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray, gray2rgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seed(2022)\n",
    "CPUS = 4 # kaggle default - https://www.kaggle.com/product-feedback/64106\n",
    "HAPPYWHALE_INPUT_DIR = \"/kaggle/input/happy-whale-and-dolphin\"\n",
    "# these are paramters to determine how to sample the initial training dataset\n",
    "MAX_INDIVIDUALS_PER_SPECIES = os.environ.get('MAX_INDIVIDUALS_PER_SPECIES', None) # none to include all\n",
    "MIN_IMAGES_PER_INDIVIDUAL_THRESHOLD = os.environ.get('MIN_IMAGES_PER_INDIVIDUAL_THRESHOLD', 0) # 0 to include all\n",
    "MAX_SAMPLE_DATA_SIZE = 10000 # change this to determine max images to include in training\n",
    "WORKING_DIR = \"/kaggle/working\"\n",
    "HEIGHT = 256\n",
    "WIDTH = 256\n",
    "VALIDATION_RATIO = .25 # used to split training and validation dataset\n",
    "IMARRAY_SIZE = (HEIGHT,WIDTH)\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84544c45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T01:45:07.313503Z",
     "iopub.status.busy": "2022-04-14T01:45:07.312755Z",
     "iopub.status.idle": "2022-04-14T01:45:07.314344Z",
     "shell.execute_reply": "2022-04-14T01:45:07.315024Z",
     "shell.execute_reply.started": "2022-04-14T01:40:16.840756Z"
    },
    "papermill": {
     "duration": 0.034939,
     "end_time": "2022-04-14T01:45:07.315209",
     "exception": false,
     "start_time": "2022-04-14T01:45:07.280270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def convert_image_to_ndarray(img_path, output_size=IMARRAY_SIZE, color='normalize_gray'):\n",
    "    '''\n",
    "    reads the `img_path` and converts it to a numpy array of size `output_size`\n",
    "    Supported Options for `color`:\n",
    "    - 'normalize_gray'\n",
    "    - 'raw_rgb'\n",
    "    \n",
    "    Returns the \n",
    "    1. normalized and standardized image\n",
    "    2. aspect ratio of the original image\n",
    "    '''\n",
    "    # read input\n",
    "    im = imread(img_path)\n",
    "    if output_size == None:\n",
    "        return im\n",
    "    aspect_ratio = float(im.shape[1] / im.shape[0])\n",
    "    resized_im = resize(im, output_size)\n",
    "    if color == 'raw_rgb':\n",
    "        return resized_im, aspect_ratio\n",
    "    elif color == 'normalize_gray':\n",
    "        # if image only has 2 channels, it's already grayscale\n",
    "        if len(resized_im.shape) == 2:\n",
    "            return resized_im / np.max(resized_im), aspect_ratio\n",
    "        # if image has 3 channels. it's rgb and needs to be converted to grayscale\n",
    "        elif len(resized_im.shape) == 3:\n",
    "            gray_img = rgb2gray(resized_im)\n",
    "            # Now normalize gray image\n",
    "            gray_norm = gray_img / np.max(gray_img)\n",
    "            return gray_norm, aspect_ratio\n",
    "        \n",
    "def convert_ndarray_img_to_maintain_aspect_ratio(ndarray_img, ar):\n",
    "    '''\n",
    "    aspect ratio is width / height\n",
    "    '''\n",
    "    new_width = ndarray_img.shape[1]*ar # new width should be aspect ratio * img width\n",
    "    new_ar_shape = (ndarray_img.shape[0], new_width)\n",
    "    return resize(ndarray_img, new_ar_shape)\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print('{0} done in {1:.3f} seconds.'.format(name, time.time() - t0))\n",
    "\n",
    "def split_df(df, num_splits, log=False):\n",
    "    \n",
    "    df_list = []\n",
    "    rows_splits = np.linspace(0, df.shape[0], num_splits+1).astype(int)\n",
    "    if log:\n",
    "        print('Split into {} parts'.format(num_splits))\n",
    "        print('Row splits:\\n{}'.format(rows_splits))\n",
    "    \n",
    "    for i in range(len(rows_splits) - 1):\n",
    "        df_list.append(df.iloc[rows_splits[i]:rows_splits[i+1]])\n",
    "        \n",
    "    return df_list[:num_splits]\n",
    "\n",
    "def split_arr(arr, num_splits, log=False):\n",
    "    rows_splits = np.linspace(0, df.shape[0], num_splits+1).astype(int)\n",
    "    if log:\n",
    "        print('Split into {} parts'.format(num_splits))\n",
    "        print('Row splits:\\n{}'.format(rows_splits))\n",
    "    \n",
    "    r_list = []\n",
    "    for i in range(len(rows_splits) - 1):\n",
    "        r_list.append(arr[rows_splits[i]:rows_splits[i+1]])\n",
    "        \n",
    "    return r_list[:num_splits]\n",
    "\n",
    "# create lambda function to construct the full path for a given image.\n",
    "# this is intended to be used on the `image` column in train.csv\n",
    "get_img_path = lambda img: os.path.join(HAPPYWHALE_INPUT_DIR, img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e8bf5db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T01:45:07.349841Z",
     "iopub.status.busy": "2022-04-14T01:45:07.349107Z",
     "iopub.status.idle": "2022-04-14T01:45:07.516185Z",
     "shell.execute_reply": "2022-04-14T01:45:07.516715Z",
     "shell.execute_reply.started": "2022-04-14T01:40:18.171624Z"
    },
    "papermill": {
     "duration": 0.186105,
     "end_time": "2022-04-14T01:45:07.516899",
     "exception": false,
     "start_time": "2022-04-14T01:45:07.330794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "train_csv_fn = \"train.csv\"\n",
    "# order by image jpg file and reset index to have deterministic index\n",
    "train_df = pd.read_csv(os.path.join(HAPPYWHALE_INPUT_DIR, train_csv_fn)).sort_values('image').reset_index()\n",
    "\n",
    "train_df.species.replace({\"globis\": \"short_finned_pilot_whale\",\n",
    "                          \"pilot_whale\": \"short_finned_pilot_whale\",\n",
    "                          \"kiler_whale\": \"killer_whale\",\n",
    "                          \"bottlenose_dolpin\": \"bottlenose_dolphin\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee7840c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T01:45:07.560462Z",
     "iopub.status.busy": "2022-04-14T01:45:07.559770Z",
     "iopub.status.idle": "2022-04-14T01:45:07.565744Z",
     "shell.execute_reply": "2022-04-14T01:45:07.565127Z",
     "shell.execute_reply.started": "2022-04-14T01:41:05.410385Z"
    },
    "papermill": {
     "duration": 0.033177,
     "end_time": "2022-04-14T01:45:07.565897",
     "exception": false,
     "start_time": "2022-04-14T01:45:07.532720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# with timer('Sampling data: '):\n",
    "#     individual_ids_by_species = pd.DataFrame(train_df[['species', 'individual_id']].value_counts()).rename({0:'count'}, axis=1)\n",
    "#     subsetted_individuals = individual_ids_by_species[individual_ids_by_species['count']>MIN_IMAGES_PER_INDIVIDUAL_THRESHOLD].reset_index()#['count'].sum()\n",
    "#     sampled_data = []\n",
    "#     for iid in subsetted_individuals.individual_id:\n",
    "#         images_of_iid = train_df[train_df['individual_id']==iid]\n",
    "#         sample = images_of_iid[:MAX_INDIVIDUALS_PER_SPECIES]\n",
    "#         sampled_data.append(sample)\n",
    "#     sampled_data_df = pd.concat(sampled_data)\n",
    "target = 'beluga'\n",
    "sampled_data_df = train_df[train_df['species']==target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b71bde6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T01:45:07.600726Z",
     "iopub.status.busy": "2022-04-14T01:45:07.599976Z",
     "iopub.status.idle": "2022-04-14T01:45:07.614903Z",
     "shell.execute_reply": "2022-04-14T01:45:07.615416Z",
     "shell.execute_reply.started": "2022-04-14T01:41:15.438720Z"
    },
    "papermill": {
     "duration": 0.034232,
     "end_time": "2022-04-14T01:45:07.615642",
     "exception": false,
     "start_time": "2022-04-14T01:45:07.581410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "delimiter = \":\"\n",
    "def setup_directories(unique_species_and_inid, log=False):\n",
    "    subdirs = ['train', 'test']\n",
    "    for subdir in subdirs:\n",
    "        for species_and_inid in unique_species_and_inid:\n",
    "            species, inid = species_and_inid.split(delimiter)\n",
    "            # create label subdirectories\n",
    "            newdir = \"{wd}/{train_or_test}/{species}/{inid}\".format(wd=WORKING_DIR,\n",
    "                                                                    train_or_test=subdir,\n",
    "                                                                    species=species,\n",
    "                                                                    inid=inid)\n",
    "            if log:\n",
    "                print('Creating: ', newdir)\n",
    "            os.makedirs(newdir, exist_ok=True)\n",
    "\n",
    "def setup_datasets(df, val_ratio=VALIDATION_RATIO, file_type=\".jpg\", log=False):\n",
    "    '''\n",
    "    Set up the working directory such that\n",
    "    folder names correspond to species class and\n",
    "    contents are the images of that species.\n",
    "    '''\n",
    "    num_saved_files = 0\n",
    "    for index, row in df.iterrows():\n",
    "        species = row['species']\n",
    "        individual_id = row['individual_id']\n",
    "        image = row['image']\n",
    "        src_img_path = get_img_path('train_images/{}'.format(image))\n",
    "        output_fn = image.split('.')[0] + file_type\n",
    "        dst_img_path = \"{wd}/{train_or_test}/{species}/{inid}/{filename}\".format(wd=WORKING_DIR,\n",
    "                                                                                 train_or_test='test' if random() < val_ratio else 'train',\n",
    "                                                                                 species=species,\n",
    "                                                                                 inid=individual_id,\n",
    "                                                                                 filename=output_fn\n",
    "                                                                             )\n",
    "        try:\n",
    "            if log:\n",
    "                    print('Saving {} to {} as {}'.format(src_img_path,\n",
    "                                                         dst_img_path,\n",
    "                                                         type(arr)))\n",
    "            if file_type == '.npy':\n",
    "                arr, ar = convert_image_to_ndarray(src_img_path, color='raw_rgb')\n",
    "                save(dst_img_path, arr)\n",
    "            elif file_type == '.jpg':\n",
    "                copyfile(src_img_path,dst_img_path)\n",
    "                \n",
    "            num_saved_files +=1\n",
    "        except Exception as e:\n",
    "            print(type(e))\n",
    "            print(e)\n",
    "            print('Skipping: ', src_img_path)\n",
    "    return num_saved_files\n",
    "\n",
    "\n",
    "def pool_setup_datasets(df, timer_str, CPUS=4, log=False, max_images_to_include=MAX_SAMPLE_DATA_SIZE):\n",
    "    df_splits = split_df(df[:max_images_to_include], num_splits=CPUS, log=log)\n",
    "    with timer(timer_str):\n",
    "        with Pool(processes=CPUS) as pool:\n",
    "            num_files_saved = pool.map(setup_datasets, df_splits)\n",
    "    total_saved = sum(num_files_saved)\n",
    "    if log:\n",
    "        print('Saved {} image arrays or image files'.format(total_saved))\n",
    "    return total_saved\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa16cef8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T01:45:07.650078Z",
     "iopub.status.busy": "2022-04-14T01:45:07.649350Z",
     "iopub.status.idle": "2022-04-14T01:45:25.455975Z",
     "shell.execute_reply": "2022-04-14T01:45:25.455046Z",
     "shell.execute_reply.started": "2022-04-14T01:41:23.590166Z"
    },
    "papermill": {
     "duration": 17.824665,
     "end_time": "2022-04-14T01:45:25.456189",
     "exception": false,
     "start_time": "2022-04-14T01:45:07.631524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 4 parts\n",
      "Row splits:\n",
      "[   0 1860 3721 5582 7443]\n",
      "setting up datasets done in 17.691 seconds.\n",
      "Saved 7443 image arrays or image files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7443"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_species_and_inids = [\"{}{}{}\".format(s,delimiter, i) for s, i in sampled_data_df.groupby(['species', 'individual_id']).agg('count').index]\n",
    "\n",
    "setup_directories(unique_species_and_inids, log=False)\n",
    "pool_setup_datasets(sampled_data_df, timer_str='setting up datasets', log=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab005f32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T01:45:25.497153Z",
     "iopub.status.busy": "2022-04-14T01:45:25.496209Z",
     "iopub.status.idle": "2022-04-14T01:45:25.499708Z",
     "shell.execute_reply": "2022-04-14T01:45:25.500254Z",
     "shell.execute_reply.started": "2022-04-14T01:42:00.077466Z"
    },
    "papermill": {
     "duration": 0.027216,
     "end_time": "2022-04-14T01:45:25.500450",
     "exception": false,
     "start_time": "2022-04-14T01:45:25.473234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'beluga:01ed73cc8026'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_species_and_inids[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c6cc01e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T01:45:25.576265Z",
     "iopub.status.busy": "2022-04-14T01:45:25.553981Z",
     "iopub.status.idle": "2022-04-14T01:45:31.523522Z",
     "shell.execute_reply": "2022-04-14T01:45:31.522895Z",
     "shell.execute_reply.started": "2022-04-14T01:42:09.792825Z"
    },
    "papermill": {
     "duration": 6.00598,
     "end_time": "2022-04-14T01:45:31.523712",
     "exception": false,
     "start_time": "2022-04-14T01:45:25.517732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import argparse\n",
    "import matplotlib\n",
    "import imghdr\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.preprocessing import image\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "def generate_from_paths_and_labels(\n",
    "        input_paths, labels, batch_size, input_size=(299, 299)):\n",
    "    num_samples = len(input_paths)\n",
    "    while 1:\n",
    "        perm = np.random.permutation(num_samples)\n",
    "        input_paths = input_paths[perm]\n",
    "        labels = labels[perm]\n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            inputs = list(map(\n",
    "                lambda x: image.load_img(x, target_size=input_size),\n",
    "                input_paths[i:i+batch_size]\n",
    "            ))\n",
    "            inputs = np.array(list(map(\n",
    "                lambda x: image.img_to_array(x),\n",
    "                inputs\n",
    "            )))\n",
    "            inputs = preprocess_input(inputs)\n",
    "            yield (inputs, labels[i:i+batch_size])\n",
    "\n",
    "\n",
    "def fine_tune(dataset_root,\n",
    "                classes,\n",
    "                result_root,\n",
    "                epochs_pre=5,\n",
    "                epochs_fine=EPOCHS,\n",
    "                batch_size_pre=32,\n",
    "                batch_size_fine=16,\n",
    "                lr_pre=1e-3,\n",
    "                lr_fine=1e-4,\n",
    "                snapshot_period_pre=1,\n",
    "                snapshot_period_fine=1,\n",
    "                split=0.8,):\n",
    "    '''\n",
    "    Reference https://github.com/otenim/Xception-with-Your-Own-Dataset\n",
    "    '''\n",
    "\n",
    "    # ====================================================\n",
    "    # Preparation\n",
    "    # ====================================================\n",
    "    # parameters\n",
    "    epochs = epochs_pre + epochs_fine\n",
    "    dataset_root = os.path.expanduser(dataset_root)\n",
    "    result_root = os.path.expanduser(result_root)\n",
    "\n",
    "    # load class names\n",
    "#     with open(classes, 'r') as f:\n",
    "#         classes = f.readlines()\n",
    "#         classes = list(map(lambda x: x.strip(), classes))\n",
    "    num_classes = len(classes)\n",
    "\n",
    "    # make input_paths and labels\n",
    "    input_paths, labels = [], []\n",
    "    for class_name in os.listdir(dataset_root):\n",
    "        class_root = os.path.join(dataset_root, class_name)\n",
    "        class_id = classes.index(class_name)\n",
    "        for path in os.listdir(class_root):\n",
    "            path = os.path.join(class_root, path)\n",
    "            if imghdr.what(path) is None:\n",
    "                # this is not an image file\n",
    "                continue\n",
    "            input_paths.append(path)\n",
    "            labels.append(class_id)\n",
    "\n",
    "    # convert to one-hot-vector format\n",
    "    labels = to_categorical(labels, num_classes=num_classes)\n",
    "\n",
    "    # convert to numpy array\n",
    "    input_paths = np.array(input_paths)\n",
    "\n",
    "    # shuffle dataset\n",
    "    perm = np.random.permutation(len(input_paths))\n",
    "    labels = labels[perm]\n",
    "    input_paths = input_paths[perm]\n",
    "\n",
    "    # split dataset for training and validation\n",
    "    border = int(len(input_paths) * split)\n",
    "    train_labels = labels[:border]\n",
    "    val_labels = labels[border:]\n",
    "    train_input_paths = input_paths[:border]\n",
    "    val_input_paths = input_paths[border:]\n",
    "    print(\"Training on %d images and labels\" % (len(train_input_paths)))\n",
    "    print(\"Validation on %d images and labels\" % (len(val_input_paths)))\n",
    "\n",
    "    # create a directory where results will be saved (if necessary)\n",
    "    if os.path.exists(result_root) is False:\n",
    "        os.makedirs(result_root)\n",
    "\n",
    "    # ====================================================\n",
    "    # Build a custom Xception\n",
    "    # ====================================================\n",
    "    # instantiate pre-trained Xception model\n",
    "    # the default input shape is (299, 299, 3)\n",
    "    # NOTE: the top classifier is not included\n",
    "    base_model = Xception(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(HEIGHT, WIDTH, 3))\n",
    "\n",
    "    # create a custom top classifier\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.inputs, outputs=predictions)\n",
    "\n",
    "    # ====================================================\n",
    "    # Train only the top classifier\n",
    "    # ====================================================\n",
    "    # freeze the body layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # compile model\n",
    "    model.compile(\n",
    "        loss=categorical_crossentropy,\n",
    "        optimizer=Adam(lr=lr_pre),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # train\n",
    "    hist_pre = model.fit_generator(\n",
    "        generator=generate_from_paths_and_labels(\n",
    "            input_paths=train_input_paths,\n",
    "            labels=train_labels,\n",
    "            batch_size=batch_size_pre\n",
    "        ),\n",
    "        steps_per_epoch=math.ceil(\n",
    "            len(train_input_paths) / batch_size_pre),\n",
    "        epochs=epochs_pre,\n",
    "        validation_data=generate_from_paths_and_labels(\n",
    "            input_paths=val_input_paths,\n",
    "            labels=val_labels,\n",
    "            batch_size=batch_size_pre\n",
    "        ),\n",
    "        validation_steps=math.ceil(\n",
    "            len(val_input_paths) / batch_size_pre),\n",
    "        verbose=1,\n",
    "        callbacks=[\n",
    "            ModelCheckpoint(\n",
    "                filepath=os.path.join(\n",
    "                    result_root,\n",
    "                    'model_pre_ep{epoch}_valloss{val_loss:.3f}.h5'),\n",
    "                period=snapshot_period_pre,\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "    model.save(os.path.join(result_root, 'model_pre_final.h5'))\n",
    "\n",
    "    # ====================================================\n",
    "    # Train the whole model\n",
    "    # ====================================================\n",
    "    # set all the layers to be trainable\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # recompile\n",
    "    model.compile(\n",
    "        optimizer=Adam(lr=lr_fine),\n",
    "        loss=categorical_crossentropy,\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    # train\n",
    "    hist_fine = model.fit_generator(\n",
    "        generator=generate_from_paths_and_labels(\n",
    "            input_paths=train_input_paths,\n",
    "            labels=train_labels,\n",
    "            batch_size=batch_size_fine\n",
    "        ),\n",
    "        steps_per_epoch=math.ceil(\n",
    "            len(train_input_paths) / batch_size_fine),\n",
    "        epochs=epochs_fine,\n",
    "        validation_data=generate_from_paths_and_labels(\n",
    "            input_paths=val_input_paths,\n",
    "            labels=val_labels,\n",
    "            batch_size=batch_size_fine\n",
    "        ),\n",
    "        validation_steps=math.ceil(\n",
    "            len(val_input_paths) / batch_size_fine),\n",
    "        verbose=1,\n",
    "        callbacks=[\n",
    "            ModelCheckpoint(\n",
    "                filepath=os.path.join(\n",
    "                    result_root,\n",
    "                    'model_fine_ep{epoch}_valloss{val_loss:.3f}.h5'),\n",
    "                period=snapshot_period_fine,\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "    model.save(os.path.join(result_root, 'model_fine_final.h5'))\n",
    "\n",
    "    # ====================================================\n",
    "    # Create & save result graphs\n",
    "    # ====================================================\n",
    "    # concatinate plot data\n",
    "    acc = hist_pre.history['accuracy']\n",
    "    val_acc = hist_pre.history['val_accuracy']\n",
    "    loss = hist_pre.history['loss']\n",
    "    val_loss = hist_pre.history['val_loss']\n",
    "    acc.extend(hist_fine.history['accuracy'])\n",
    "    val_acc.extend(hist_fine.history['val_accuracy'])\n",
    "    loss.extend(hist_fine.history['loss'])\n",
    "    val_loss.extend(hist_fine.history['val_loss'])\n",
    "\n",
    "    # save graph image\n",
    "    plt.plot(range(epochs), acc, marker='.', label='accuracy')\n",
    "    plt.plot(range(epochs), val_acc, marker='.', label='val_accuracy')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.savefig(os.path.join(result_root, 'accuracy.png'))\n",
    "    plt.clf()\n",
    "\n",
    "    plt.plot(range(epochs), loss, marker='.', label='loss')\n",
    "    plt.plot(range(epochs), val_loss, marker='.', label='val_loss')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.savefig(os.path.join(result_root, 'loss.png'))\n",
    "    plt.clf()\n",
    "\n",
    "    # save plot data as pickle file\n",
    "    plot = {\n",
    "        'accuracy': acc,\n",
    "        'val_accuracy': val_acc,\n",
    "        'loss': loss,\n",
    "        'val_loss': val_loss,\n",
    "    }\n",
    "    with open(os.path.join(result_root, 'plot.dump'), 'wb') as f:\n",
    "        pkl.dump(plot, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42e5f95f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T01:45:31.564750Z",
     "iopub.status.busy": "2022-04-14T01:45:31.562292Z",
     "iopub.status.idle": "2022-04-14T11:06:55.867951Z",
     "shell.execute_reply": "2022-04-14T11:06:55.867211Z"
    },
    "papermill": {
     "duration": 33684.326648,
     "end_time": "2022-04-14T11:06:55.868126",
     "exception": false,
     "start_time": "2022-04-14T01:45:31.541478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 4475 images and labels\n",
      "Validation on 1119 images and labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-14 01:45:31.850012: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 2s 0us/step\n",
      "83697664/83683744 [==============================] - 2s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "2022-04-14 01:45:36.882970: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "140/140 [==============================] - 1015s 7s/step - loss: 6.3810 - accuracy: 0.0147 - val_loss: 6.1488 - val_accuracy: 0.0268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "140/140 [==============================] - 884s 6s/step - loss: 5.5833 - accuracy: 0.0360 - val_loss: 5.9575 - val_accuracy: 0.0349\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 885s 6s/step - loss: 5.1242 - accuracy: 0.0594 - val_loss: 5.9834 - val_accuracy: 0.0518\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 909s 6s/step - loss: 4.6812 - accuracy: 0.0834 - val_loss: 6.1426 - val_accuracy: 0.0474\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 882s 6s/step - loss: 4.1962 - accuracy: 0.1263 - val_loss: 6.2497 - val_accuracy: 0.0483\n",
      "Epoch 1/10\n",
      "280/280 [==============================] - 2876s 10s/step - loss: 4.5591 - accuracy: 0.1057 - val_loss: 6.0973 - val_accuracy: 0.0760\n",
      "Epoch 2/10\n",
      "280/280 [==============================] - 2867s 10s/step - loss: 3.4203 - accuracy: 0.2579 - val_loss: 6.9789 - val_accuracy: 0.0813\n",
      "Epoch 3/10\n",
      "280/280 [==============================] - 2815s 10s/step - loss: 2.6154 - accuracy: 0.4291 - val_loss: 7.3568 - val_accuracy: 0.0840\n",
      "Epoch 4/10\n",
      "280/280 [==============================] - 2821s 10s/step - loss: 1.8812 - accuracy: 0.6109 - val_loss: 7.9462 - val_accuracy: 0.0822\n",
      "Epoch 5/10\n",
      "280/280 [==============================] - 2836s 10s/step - loss: 1.2586 - accuracy: 0.7526 - val_loss: 8.2202 - val_accuracy: 0.0822\n",
      "Epoch 6/10\n",
      "280/280 [==============================] - 2895s 10s/step - loss: 0.7644 - accuracy: 0.8670 - val_loss: 8.7776 - val_accuracy: 0.0733\n",
      "Epoch 7/10\n",
      "280/280 [==============================] - 2972s 11s/step - loss: 0.4651 - accuracy: 0.9265 - val_loss: 9.0002 - val_accuracy: 0.0965\n",
      "Epoch 8/10\n",
      "280/280 [==============================] - 3011s 11s/step - loss: 0.2611 - accuracy: 0.9660 - val_loss: 9.1594 - val_accuracy: 0.0831\n",
      "Epoch 9/10\n",
      "280/280 [==============================] - 3010s 11s/step - loss: 0.1489 - accuracy: 0.9841 - val_loss: 9.2640 - val_accuracy: 0.0947\n",
      "Epoch 10/10\n",
      "280/280 [==============================] - 2984s 11s/step - loss: 0.0922 - accuracy: 0.9928 - val_loss: 9.6260 - val_accuracy: 0.0813\n"
     ]
    }
   ],
   "source": [
    "individual_ids_sorted = sorted(os.listdir('{}/train/{}'.format(WORKING_DIR, target)))\n",
    "fine_tune('{}/train/{}'.format(WORKING_DIR, target), individual_ids_sorted, WORKING_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42340236",
   "metadata": {
    "papermill": {
     "duration": 1.485904,
     "end_time": "2022-04-14T11:06:58.820764",
     "exception": false,
     "start_time": "2022-04-14T11:06:57.334860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 33730.395518,
   "end_time": "2022-04-14T11:07:03.782664",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-14T01:44:53.387146",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
