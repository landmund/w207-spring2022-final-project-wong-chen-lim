{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af96550e",
   "metadata": {
    "papermill": {
     "duration": 0.014944,
     "end_time": "2022-04-07T21:18:50.340739",
     "exception": false,
     "start_time": "2022-04-07T21:18:50.325795",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Whales and Dolphin ID\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1278ea4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T21:18:50.375956Z",
     "iopub.status.busy": "2022-04-07T21:18:50.374211Z",
     "iopub.status.idle": "2022-04-07T21:18:52.734688Z",
     "shell.execute_reply": "2022-04-07T21:18:52.733986Z",
     "shell.execute_reply.started": "2022-04-07T21:09:11.987113Z"
    },
    "papermill": {
     "duration": 2.379228,
     "end_time": "2022-04-07T21:18:52.734858",
     "exception": false,
     "start_time": "2022-04-07T21:18:50.355630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "from numpy import save, load\n",
    "from random import seed\n",
    "from os import listdir\n",
    "from shutil import copyfile\n",
    "from random import seed\n",
    "from random import random\n",
    "\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from contextlib import contextmanager\n",
    "from multiprocessing.pool import ThreadPool, Pool\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray, gray2rgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seed(2022)\n",
    "CPUS = 4 # kaggle default - https://www.kaggle.com/product-feedback/64106\n",
    "HAPPYWHALE_INPUT_DIR = \"/kaggle/input/happy-whale-and-dolphin\"\n",
    "# these are paramters to determine how to sample the initial training dataset\n",
    "MAX_INDIVIDUALS_PER_SPECIES = os.environ.get('MAX_INDIVIDUALS_PER_SPECIES', 5)\n",
    "MAX_IMAGES_PER_INDIVIDUAL_THRESHOLD = os.environ.get('MAX_IMAGES_PER_INDIVIDUAL_THRESHOLD', 5)\n",
    "MAX_SAMPLE_DATA_SIZE = 10000 # change this to determine max images to include in training\n",
    "WORKING_DIR = \"/kaggle/working\"\n",
    "HEIGHT = 256\n",
    "WIDTH = 256\n",
    "VALIDATION_RATIO = .25 # used to split training and validation dataset\n",
    "IMARRAY_SIZE = (HEIGHT,WIDTH)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a719061",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T21:18:52.767931Z",
     "iopub.status.busy": "2022-04-07T21:18:52.767382Z",
     "iopub.status.idle": "2022-04-07T21:18:52.782242Z",
     "shell.execute_reply": "2022-04-07T21:18:52.782709Z",
     "shell.execute_reply.started": "2022-04-07T21:09:14.816497Z"
    },
    "papermill": {
     "duration": 0.032871,
     "end_time": "2022-04-07T21:18:52.782852",
     "exception": false,
     "start_time": "2022-04-07T21:18:52.749981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def convert_image_to_ndarray(img_path, output_size=IMARRAY_SIZE, color='normalize_gray'):\n",
    "    '''\n",
    "    reads the `img_path` and converts it to a numpy array of size `output_size`\n",
    "    Supported Options for `color`:\n",
    "    - 'normalize_gray'\n",
    "    - 'raw_rgb'\n",
    "    \n",
    "    Returns the \n",
    "    1. normalized and standardized image\n",
    "    2. aspect ratio of the original image\n",
    "    '''\n",
    "    # read input\n",
    "    im = imread(img_path)\n",
    "    if output_size == None:\n",
    "        return im\n",
    "    aspect_ratio = float(im.shape[1] / im.shape[0])\n",
    "    resized_im = resize(im, output_size)\n",
    "    if color == 'raw_rgb':\n",
    "        return resized_im, aspect_ratio\n",
    "    elif color == 'normalize_gray':\n",
    "        # if image only has 2 channels, it's already grayscale\n",
    "        if len(resized_im.shape) == 2:\n",
    "            return resized_im / np.max(resized_im), aspect_ratio\n",
    "        # if image has 3 channels. it's rgb and needs to be converted to grayscale\n",
    "        elif len(resized_im.shape) == 3:\n",
    "            gray_img = rgb2gray(resized_im)\n",
    "            # Now normalize gray image\n",
    "            gray_norm = gray_img / np.max(gray_img)\n",
    "            return gray_norm, aspect_ratio\n",
    "        \n",
    "def convert_ndarray_img_to_maintain_aspect_ratio(ndarray_img, ar):\n",
    "    '''\n",
    "    aspect ratio is width / height\n",
    "    '''\n",
    "    new_width = ndarray_img.shape[1]*ar # new width should be aspect ratio * img width\n",
    "    new_ar_shape = (ndarray_img.shape[0], new_width)\n",
    "    return resize(ndarray_img, new_ar_shape)\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print('{0} done in {1:.3f} seconds.'.format(name, time.time() - t0))\n",
    "\n",
    "def split_df(df, num_splits, log=False):\n",
    "    \n",
    "    df_list = []\n",
    "    rows_splits = np.linspace(0, df.shape[0], num_splits+1).astype(int)\n",
    "    if log:\n",
    "        print('Split into {} parts'.format(num_splits))\n",
    "        print('Row splits:\\n{}'.format(rows_splits))\n",
    "    \n",
    "    for i in range(len(rows_splits) - 1):\n",
    "        df_list.append(df.iloc[rows_splits[i]:rows_splits[i+1]])\n",
    "        \n",
    "    return df_list[:num_splits]\n",
    "\n",
    "def split_arr(arr, num_splits, log=False):\n",
    "    rows_splits = np.linspace(0, df.shape[0], num_splits+1).astype(int)\n",
    "    if log:\n",
    "        print('Split into {} parts'.format(num_splits))\n",
    "        print('Row splits:\\n{}'.format(rows_splits))\n",
    "    \n",
    "    r_list = []\n",
    "    for i in range(len(rows_splits) - 1):\n",
    "        r_list.append(arr[rows_splits[i]:rows_splits[i+1]])\n",
    "        \n",
    "    return r_list[:num_splits]\n",
    "\n",
    "# create lambda function to construct the full path for a given image.\n",
    "# this is intended to be used on the `image` column in train.csv\n",
    "get_img_path = lambda img: os.path.join(HAPPYWHALE_INPUT_DIR, img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890b4185",
   "metadata": {
    "papermill": {
     "duration": 0.014615,
     "end_time": "2022-04-07T21:18:52.811926",
     "exception": false,
     "start_time": "2022-04-07T21:18:52.797311",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Sample data\n",
    "\n",
    "Sample / Select images to be used for training in the challenge’s `train.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3d27abc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T21:18:52.844079Z",
     "iopub.status.busy": "2022-04-07T21:18:52.843549Z",
     "iopub.status.idle": "2022-04-07T21:18:53.012069Z",
     "shell.execute_reply": "2022-04-07T21:18:53.012733Z",
     "shell.execute_reply.started": "2022-04-07T21:09:14.835594Z"
    },
    "papermill": {
     "duration": 0.186238,
     "end_time": "2022-04-07T21:18:53.012897",
     "exception": false,
     "start_time": "2022-04-07T21:18:52.826659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "train_csv_fn = \"train.csv\"\n",
    "# order by image jpg file and reset index to have deterministic index\n",
    "train_df = pd.read_csv(os.path.join(HAPPYWHALE_INPUT_DIR, train_csv_fn)).sort_values('image').reset_index()\n",
    "\n",
    "train_df.species.replace({\"globis\": \"short_finned_pilot_whale\",\n",
    "                          \"pilot_whale\": \"short_finned_pilot_whale\",\n",
    "                          \"kiler_whale\": \"killer_whale\",\n",
    "                          \"bottlenose_dolpin\": \"bottlenose_dolphin\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b13f79f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T21:18:53.052171Z",
     "iopub.status.busy": "2022-04-07T21:18:53.051625Z",
     "iopub.status.idle": "2022-04-07T21:19:04.387450Z",
     "shell.execute_reply": "2022-04-07T21:19:04.387898Z",
     "shell.execute_reply.started": "2022-04-07T21:09:15.025017Z"
    },
    "papermill": {
     "duration": 11.360268,
     "end_time": "2022-04-07T21:19:04.388057",
     "exception": false,
     "start_time": "2022-04-07T21:18:53.027789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling data:  done in 11.335 seconds.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with timer('Sampling data: '):\n",
    "    individual_ids_by_species = pd.DataFrame(train_df[['species', 'individual_id']].value_counts()).rename({0:'count'}, axis=1)\n",
    "    subsetted_individuals = individual_ids_by_species[individual_ids_by_species['count']>MAX_IMAGES_PER_INDIVIDUAL_THRESHOLD].reset_index()#['count'].sum()\n",
    "    sampled_data = []\n",
    "    for iid in subsetted_individuals.individual_id:\n",
    "        images_of_iid = train_df[train_df['individual_id']==iid]\n",
    "        sample = images_of_iid[:MAX_INDIVIDUALS_PER_SPECIES]\n",
    "        sampled_data.append(sample)\n",
    "    sampled_data_df = pd.concat(sampled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6de391e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T21:19:04.420117Z",
     "iopub.status.busy": "2022-04-07T21:19:04.419570Z",
     "iopub.status.idle": "2022-04-07T21:19:04.434452Z",
     "shell.execute_reply": "2022-04-07T21:19:04.433979Z",
     "shell.execute_reply.started": "2022-04-07T21:09:27.404694Z"
    },
    "papermill": {
     "duration": 0.032107,
     "end_time": "2022-04-07T21:19:04.434581",
     "exception": false,
     "start_time": "2022-04-07T21:19:04.402474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>image</th>\n",
       "      <th>species</th>\n",
       "      <th>individual_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>0046ceef89b3fc.jpg</td>\n",
       "      <td>minke_whale</td>\n",
       "      <td>37c7aba965a5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62</td>\n",
       "      <td>005e53b1b6aada.jpg</td>\n",
       "      <td>minke_whale</td>\n",
       "      <td>37c7aba965a5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>174</td>\n",
       "      <td>0106d276033b78.jpg</td>\n",
       "      <td>minke_whale</td>\n",
       "      <td>37c7aba965a5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>226</td>\n",
       "      <td>014ba64e8ce8ec.jpg</td>\n",
       "      <td>minke_whale</td>\n",
       "      <td>37c7aba965a5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>253</td>\n",
       "      <td>01637f0b588ed8.jpg</td>\n",
       "      <td>minke_whale</td>\n",
       "      <td>37c7aba965a5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8280</th>\n",
       "      <td>8280</td>\n",
       "      <td>29778c02fc2154.jpg</td>\n",
       "      <td>humpback_whale</td>\n",
       "      <td>5fb723f0717e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9576</th>\n",
       "      <td>9576</td>\n",
       "      <td>30355c9b68dde3.jpg</td>\n",
       "      <td>humpback_whale</td>\n",
       "      <td>5fb723f0717e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12059</th>\n",
       "      <td>12059</td>\n",
       "      <td>3cfb490bff6e3b.jpg</td>\n",
       "      <td>humpback_whale</td>\n",
       "      <td>5fb723f0717e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29928</th>\n",
       "      <td>29928</td>\n",
       "      <td>96826b9a212fdd.jpg</td>\n",
       "      <td>humpback_whale</td>\n",
       "      <td>5fb723f0717e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30846</th>\n",
       "      <td>30846</td>\n",
       "      <td>9b0d796a1dd7bd.jpg</td>\n",
       "      <td>humpback_whale</td>\n",
       "      <td>5fb723f0717e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6750 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index               image         species individual_id\n",
       "48        48  0046ceef89b3fc.jpg     minke_whale  37c7aba965a5\n",
       "62        62  005e53b1b6aada.jpg     minke_whale  37c7aba965a5\n",
       "174      174  0106d276033b78.jpg     minke_whale  37c7aba965a5\n",
       "226      226  014ba64e8ce8ec.jpg     minke_whale  37c7aba965a5\n",
       "253      253  01637f0b588ed8.jpg     minke_whale  37c7aba965a5\n",
       "...      ...                 ...             ...           ...\n",
       "8280    8280  29778c02fc2154.jpg  humpback_whale  5fb723f0717e\n",
       "9576    9576  30355c9b68dde3.jpg  humpback_whale  5fb723f0717e\n",
       "12059  12059  3cfb490bff6e3b.jpg  humpback_whale  5fb723f0717e\n",
       "29928  29928  96826b9a212fdd.jpg  humpback_whale  5fb723f0717e\n",
       "30846  30846  9b0d796a1dd7bd.jpg  humpback_whale  5fb723f0717e\n",
       "\n",
       "[6750 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a23b74f",
   "metadata": {
    "papermill": {
     "duration": 0.01495,
     "end_time": "2022-04-07T21:19:04.464520",
     "exception": false,
     "start_time": "2022-04-07T21:19:04.449570",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Set up directories and datasets\n",
    "\n",
    "Set up the working directory such that folder names correspond to species class and contents are the images of that species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ef39c01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T21:19:04.498123Z",
     "iopub.status.busy": "2022-04-07T21:19:04.497165Z",
     "iopub.status.idle": "2022-04-07T21:19:04.510767Z",
     "shell.execute_reply": "2022-04-07T21:19:04.510309Z",
     "shell.execute_reply.started": "2022-04-07T21:09:27.424537Z"
    },
    "papermill": {
     "duration": 0.031047,
     "end_time": "2022-04-07T21:19:04.510892",
     "exception": false,
     "start_time": "2022-04-07T21:19:04.479845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def setup_directories(unique_species, log=False):\n",
    "    subdirs = ['train', 'test']\n",
    "    for subdir in subdirs:\n",
    "        for species in unique_species:\n",
    "            # create label subdirectories\n",
    "            newdir = \"{}/{}/{}\".format(WORKING_DIR, subdir, species)\n",
    "            if log:\n",
    "                print('Creating: ', newdir)\n",
    "            os.makedirs(newdir, exist_ok=True)\n",
    "\n",
    "def setup_datasets(df, val_ratio=VALIDATION_RATIO, file_type=\".jpg\", log=False):\n",
    "    '''\n",
    "    Set up the working directory such that\n",
    "    folder names correspond to species class and\n",
    "    contents are the images of that species.\n",
    "    '''\n",
    "    num_saved_files = 0\n",
    "    for index, row in df.iterrows():\n",
    "        label = row['species']\n",
    "        image = row['image']\n",
    "        src_img_path = get_img_path('train_images/{}'.format(image))\n",
    "        output_fn = image.split('.')[0] + file_type\n",
    "        dst_img_path = \"{working_dir}/{dataset}/{label}/{filename}\".format(working_dir=WORKING_DIR,\n",
    "                                                                              dataset='test' if random() < val_ratio else 'train',\n",
    "                                                                              label=label,\n",
    "                                                                              filename=output_fn,\n",
    "                                                                              file_type=file_type\n",
    "                                                                             )\n",
    "        try:\n",
    "            if log:\n",
    "                    print('Saving {} to {} as {}'.format(src_img_path,\n",
    "                                                         dst_img_path,\n",
    "                                                         type(arr)))\n",
    "            if file_type == '.npy':\n",
    "                arr, ar = convert_image_to_ndarray(src_img_path, color='raw_rgb')\n",
    "                save(dst_img_path, arr)\n",
    "            elif file_type == '.jpg':\n",
    "                copyfile(src_img_path,dst_img_path)\n",
    "                \n",
    "            num_saved_files +=1\n",
    "        except Exception as e:\n",
    "            print(type(e))\n",
    "            print(e)\n",
    "            print('Skipping: ', src_img_path)\n",
    "    return num_saved_files\n",
    "\n",
    "\n",
    "def pool_setup_datasets(df, timer_str, CPUS=4, log=False, max_images_to_include=MAX_SAMPLE_DATA_SIZE):\n",
    "    df_splits = split_df(df[:max_images_to_include], num_splits=CPUS, log=log)\n",
    "    with timer(timer_str):\n",
    "        with Pool(processes=CPUS) as pool:\n",
    "            num_files_saved = pool.map(setup_datasets, df_splits)\n",
    "    total_saved = sum(num_files_saved)\n",
    "    if log:\n",
    "        print('Saved {} image arrays or image files'.format(total_saved))\n",
    "    return total_saved\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59a416d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T21:19:04.547638Z",
     "iopub.status.busy": "2022-04-07T21:19:04.546688Z",
     "iopub.status.idle": "2022-04-07T21:19:31.672405Z",
     "shell.execute_reply": "2022-04-07T21:19:31.671893Z",
     "shell.execute_reply.started": "2022-04-07T21:09:27.440277Z"
    },
    "papermill": {
     "duration": 27.14614,
     "end_time": "2022-04-07T21:19:31.672549",
     "exception": false,
     "start_time": "2022-04-07T21:19:04.526409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 4 parts\n",
      "Row splits:\n",
      "[   0 1687 3375 5062 6750]\n",
      "setting up datasets done in 27.116 seconds.\n",
      "Saved 6750 image arrays or image files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6750"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_species = sorted(sampled_data_df['species'].unique())\n",
    "\n",
    "setup_directories(unique_species, log=False)\n",
    "pool_setup_datasets(sampled_data_df, timer_str='setting up datasets', log=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc9c224",
   "metadata": {
    "papermill": {
     "duration": 0.959038,
     "end_time": "2022-04-07T21:19:32.648540",
     "exception": false,
     "start_time": "2022-04-07T21:19:31.689502",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Develop a CNN model.\n",
    "\n",
    "\n",
    "\n",
    "Create an ImageDataGenerator to create a train iterator using flow_from_directory and use fit_generator to fit the CNN using a generator instead of raw data.\n",
    "\n",
    "This is needed because the training images consists of 60GB, which is too large for memory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bef77104",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T21:19:32.890274Z",
     "iopub.status.busy": "2022-04-07T21:19:32.889408Z",
     "iopub.status.idle": "2022-04-07T21:19:39.081276Z",
     "shell.execute_reply": "2022-04-07T21:19:39.080755Z",
     "shell.execute_reply.started": "2022-04-07T21:09:27.816358Z"
    },
    "papermill": {
     "duration": 6.221563,
     "end_time": "2022-04-07T21:19:39.081413",
     "exception": false,
     "start_time": "2022-04-07T21:19:32.859850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# baseline model for the dogs vs cats dataset\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc3b6925",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T21:19:39.132051Z",
     "iopub.status.busy": "2022-04-07T21:19:39.131107Z",
     "iopub.status.idle": "2022-04-07T21:19:39.133675Z",
     "shell.execute_reply": "2022-04-07T21:19:39.133170Z",
     "shell.execute_reply.started": "2022-04-07T21:18:18.921241Z"
    },
    "papermill": {
     "duration": 0.035543,
     "end_time": "2022-04-07T21:19:39.133793",
     "exception": false,
     "start_time": "2022-04-07T21:19:39.098250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(HEIGHT, WIDTH, 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(32, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile model\n",
    "    opt = SGD(learning_rate=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "    # plot loss\n",
    "    pyplot.subplot(211)\n",
    "    pyplot.title('Cross Entropy Loss')\n",
    "    pyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "    # plot accuracy\n",
    "    pyplot.subplot(212)\n",
    "    pyplot.title('Classification Accuracy')\n",
    "    pyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "    # save plot to file\n",
    "    filename = sys.argv[0].split('/')[-1]\n",
    "    pyplot.show()\n",
    "    pyplot.savefig(filename + '_plot.png')\n",
    "    pyplot.close()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "    # define model\n",
    "    model = define_model()\n",
    "    # create data generator\n",
    "    datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "    # prepare iterators\n",
    "    train_it = datagen.flow_from_directory('{}/train/'.format(WORKING_DIR),\n",
    "                                           class_mode='binary',\n",
    "                                           batch_size=64,\n",
    "                                           target_size=IMARRAY_SIZE)\n",
    "    test_it = datagen.flow_from_directory('{}/test/'.format(WORKING_DIR),\n",
    "                                          class_mode='binary',\n",
    "                                          batch_size=64,\n",
    "                                          target_size=IMARRAY_SIZE)\n",
    "    # fit model\n",
    "    history = model.fit(train_it, steps_per_epoch=len(train_it),\n",
    "        validation_data=test_it, validation_steps=len(test_it), epochs=20, verbose=0)\n",
    "    # evaluate model\n",
    "    _, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "    print('> %.3f' % (acc * 100.0))\n",
    "    # learning curves\n",
    "    summarize_diagnostics(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53fb41e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T21:19:39.171063Z",
     "iopub.status.busy": "2022-04-07T21:19:39.170336Z",
     "iopub.status.idle": "2022-04-08T00:45:03.903394Z",
     "shell.execute_reply": "2022-04-08T00:45:03.904233Z"
    },
    "papermill": {
     "duration": 12324.755163,
     "end_time": "2022-04-08T00:45:03.905446",
     "exception": false,
     "start_time": "2022-04-07T21:19:39.150283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-07 21:19:39.201798: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5077 images belonging to 21 classes.\n",
      "Found 1673 images belonging to 21 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-07 21:19:48.104196: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/engine/training.py:2006: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 25.941\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d193909",
   "metadata": {
    "papermill": {
     "duration": 0.018352,
     "end_time": "2022-04-08T00:45:03.942498",
     "exception": false,
     "start_time": "2022-04-08T00:45:03.924146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12385.980342,
   "end_time": "2022-04-08T00:45:07.112341",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-07T21:18:41.131999",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
